0 - ABSTRACT
** Système mixte -> Système combinant l'interprétation et la compilation juste-à-temps (JIT) dans le but de gagner en vitesse
** Règle générale, un interpréteur c'est lent comparé à un système mixte
** Règle générale, un système mixte est énormément plus dur à mettre en place qu'un interpréteur (VRAI!)
** But du papier est de montrer comment un JIT peut être intégré à un interpréteur

I - INTRODUCTION
** On ne discute que d'interpréteurs type machine virtuel, c'est-à-dire ceux qui prennent en entrée une représentation intermédiaire
   d'un programme (pensons bytecode). (NOTE: Devrait décrire un peu plus ce qu'est une bonne représentation intermédiaire pour
   un interpréteur (flat). Les compilateurs modernes utilisent aussi une représentation intermédiaire (AST), mais elle ne se prête
   pas du tout à l'interprétation)
** Gros problème 1: Big Bang
	-> En gros, l'intégration d'un JIT est longue et ardue.
** Gros problème 2: Compilation de régions "froides"
	-> On pose la question: Comment discriminer les régions "chaude" et "froides" d'un programme pour ne pas avoir à compiler
      du code qui pourrait ne jamais rouler? (Ajoutons qu'en plus de la perte de temps en compilation, si l'espace est limité,
      il risque d'avoir un gaspillement au niveau de l'espace utilisé.)
** Définition: Trace = Chemin (suite d'instructions/de blocs de base) fréquemment exécuté
** Le système proposé se base sur les traces et non les méthodes d'un programme
** Développement (les auteurs ont modifiés une implémentation de la JVM, JamVM):
	-> Chaque exécution d'instructions virtuelles devient une fonction
	-> Identification d'une approximation de ce qu'est un bloc de base
	-> Implémentation d'un identificateur et "dispatcher" de traces
	-> Ajout de fonctionnalités pour lier les traces ensemble
	-> Implémentation d'un compilateur de traces
	-> (On voit ici qu'ils ont travaillé à un niveau bien plus élevé que le mien)
	-> (l'idée d'un système orienté trace est, par contre, très intéressante)
   
II - INTERPRETER AND JIT BACKGROUND
** Interpreter Dispatch
	* Def : Un monstrueux switch...case
	+ Facile et rapide à implémenter
	+ Portable
	- LENT (trop d'overhead)
	
** Direct Threading
	* Def : Chaque instruction virtuelle est représentée par une adresse dans une table (nommée DTT).
			On initialise un PC virtuelau début du DTT et on saute à cette adresse. À la fin de 
			l'instruction virtuelle: goto *vPC++ (Eeewwwwww!)
	+ Un peu plus rapide que l'approche précédente
	- Ne peut être fait qu'à l'aide de GNU C, donc non portable

** Direct Call Threading
	* Def : Utiliser un tableau de pointeur de fonctions. Par contre, il semble que cette approche
			requiert un peu de magie pour que le retour d'une fonction soit rapide...
	+ Rapide
	- Non portable

** Subroutine Threading
	* Def : Semble augmenter l'approche direct call threading en insérant des informations sur le contexte dans
            la table de dispatch. Ceci permet d'améliorer les performances au niveau des branchements
            indirects étant donné que le code généré fera dorénavant toujours les bonnes prédictions, 
            il n'aura donc plus à vider le pipeline lorsqu'il se trompe dans sa prédiction de branche
	
** Selective Inlining
	* Def : Construction de "superinstructions"... (Lire référence, car rien n'est expliqué)

** Traces
	* On présente plus quelque chose qui existe que l'idée générale
	* NET : Découvre une trace en suivant le chemin inverse d'un branchement à partir de sa destination

** JIT Compilation
	* Def : Commence par interpréter une représentation intermédiaire et, par la suite, compile
			en code natif.
	=> La compilation de régions "froides" peut nuire à l'analyse du flux de données
	=> Idéalement, couplé à un profiler qui détecte les méthodes les plus "chaudes", celles à compiler en premier
	=> Changer un JIT basé sur les méthodes pour un JIT basé sur les traces est une tâche colossale, car une trace
	   ne débute pas et ne finit par nécessairement au début et à la fin d'une méthode.

III DESIGN AND IMPLEMENTATION
    * Ils instrumentent JamVM en utilisant une variante de Direct Call Threading/Subroutine Threading
        -> Tableau de pointeurs de "dispatcher"
        - Dispatcher contient : Corps de région (possiblement fonction, mais pas nécessairement dans l'optique de traces)
                                "Preworker" : Addresse de la routine d'instrumentation à appeler avant l'exécution de la région
                                "Postworker" : Addresse de la routine d'instrumentation à appeler après l'exécution de la région
                                "Payload" : Données utiles pour le profilage
    * Stratégie pour réduire la latence lors de chargement de fonction :
        -> Avoir un dispatcher global pour chaque type d'instruction au départ, puis, après l'instrumentation initiale, 
           le postworker crée une instance spécifique d'un "block discovery dispatcher" 
           (bien pensé, mais agit à un niveau trop haut pour que ça me soit utile)
    * Fait une détection de blocs linéaires c.-à.-d. bloc se terminant sur des branchements (un bloc de base peut aussi se terminer sur des étiquettes)
        # L'idée est intéressante et très certainement à adopter si je décide de basé mon dynarec sur les traces. Par
          contre, je ne suis pas sûr que c'est quelque chose que je veux faire. À ce point-ci de ma lecture, ma grande crainte est de
          savoir comment marche l'allcation de registres dans un tel modèle. Les traces ont l'air beaucoup plus chargées en contenu que
          les blocs de base. L'allocation de registres pour des blocs de bases est déjà assez NP-complet!
    * Trace détectée quand : - Suite de 100+ instructions (à penser pour mon projet...)
                             - Cycle trouvé
    * Code généré pour une trace quand elle a roulée au moins 5 fois (encore une fois, c'est une bonne idée à intégrer dans mon projet)
    * À la fin d'une trace, le postworker tente de "linker" cette trace avec celle qui la suit dans l'exécution pour ne pas
      avoir à repasser par l'interpréteur
    # À ce point-ci, je commence à penser que le modèle présenté s'apparente à du "profile-guided optimization". Tout du moins, il
      bénéficirait sûrement d'une période d'entraînement.
    * Ils mentionnent que leur système génère un mapping simple de registres... 
        -> Leur sytème génère de l'assembleur PowerPC, il semble donc qu'ils on assez de registres pour leurs besoins
    * Ils mentionnent que les boucles sont optimisés, car elles forment des traces faciles à détecter. 
        #(L'idée de faire des optimisations entre blocs de base est intéressante, mais je n'aurais pas assez de temps pour me rendre à ce point dans mon projet)
    * Ils mentionnent des optimisations possibles pour des fonctions polymorphiques (trop haut niveau pour mon projet)
           
IV - EXPERIMENTAL RESULTS
    * En gros, on voit que ça marche bien vu que le système passe plus de temps à exécuter du code natif

V - RELATED WORK
** Système similaire : Hotpath
	-> Se concentre plus sur l'optimisation que l'intégration

VI - CONCLUSIONS AND FUTURE WORK
    * Rien de vraiment inspirant